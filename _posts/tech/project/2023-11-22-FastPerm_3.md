---
layout: post
title: "scRNA-seq 데이터 순열 검정 프로그램, FastPerm 제작기 (3)"
date: 2023-11-22 00:00:00 +0900
categories: 
  - tech
  - project
related_posts:
  - _posts/tech/project/2023-11-14-FastPerm_1.md
  - _posts/tech/project/2023-11-17-FastPerm_2.md
---

* toc
{:toc}


본 포스트에서는 C++로 Permutation test를 수행하는 scRNA-seq data 통계 분석 프로그램인 FastPerm을 제작한 과정을 다룹니다. 여기에서는 프로그램의 자세한 동작보다, **어떤 아이디어로 문제를 해결했는지**를 위주로 다루려고 합니다.


## 가장 큰 난관 
---

프로그램은 다음과 같은 과정으로 데이터를 처리합니다.
1. RNA count matrix, cell annotation, sample annotation, 총 3가지 인풋 데이터를 받음
2. Count Matrix 데이터를 pseudobulk하여, 같은 샘플에 속한 cell끼리 aggregation
3. pseudobulk table을 cpm으로 normalization
4. case와 control간 log2 fold change값들 구하기
5. permutation (Count Matrix를 셔플하여, **N회만큼** 2-4 과정을 반복)
6. gene별로 lfc의 rank를 구해 p-value 도출

가장 오래 걸리는 병목 작업은 무엇보다 몇십만번씩 반복되는 permutation 과정이었습니다. Permutation은 `pseudobulk` -> `cpm normalization` -> `lfc 계산 및 rank 비교`, 이 3가지 과정을 한 세트로 하여 수십만회 반복됩니다. 실험 결과 가장 오래 걸리는 병목 구간은 pseudobulk였고, 따라서 알고리즘을 개선하여 이를 빠르게 만드는 것을 목표로 설정했습니다.

결론적으로, 2가지 방식을 활용해 **연산 속도를 약 10배 이상 빠르게** 만들었습니다. 하나는 멀티스레딩이고, 다른 하나는 sparse matrix를 non-zero count만 남기는 방식으로 변환하는 방법입니다.


### Pseudobulk의 세부 과정
---

![](https://axqxbktknqat.objectstorage.ap-chuncheon-1.oci.customer-oci.com/p/x3c6dl2qfNZsDPc-JZrqIhRn3xzFhMvEz_7wHM1FFXpkxE8_wMXctQZCts4NVm76/n/axqxbktknqat/b/image_bucket/o/blog/FastPerm/3_FastPerm_3_1.png)

pseudobulk 과정은 그림a에 나타난 바와 같이, 같은 색(sample)으로 표시된 열(cell)끼리 row-wise하게 값들을 합치는 과정입니다. 
마찬가지로, 그림b에 나타난 permutation 과정에서는 서로의 열을 섞어준 후 **임의의 색(샘플)으로 분배**하여 row-wise하게 값들을 합칩니다.

![](https://axqxbktknqat.objectstorage.ap-chuncheon-1.oci.customer-oci.com/p/x3c6dl2qfNZsDPc-JZrqIhRn3xzFhMvEz_7wHM1FFXpkxE8_wMXctQZCts4NVm76/n/axqxbktknqat/b/image_bucket/o/blog/FastPerm/3_FastPerm_3_2.gif)

구현 차원에서는 위의 gif처럼 0이 아닌 값들을 순차적으로 누산하게 됩니다.


### R에서의 구현 방식
---

R 스크립트에서 count matrix를 aggregation할 때는 `rowSum()`이나 `aggregate.Matrix()` 함수를 사용합니다. 두 방식 모두 세부적으로 살펴보면 행렬곱으로 구현되어 있습니다.

![](https://axqxbktknqat.objectstorage.ap-chuncheon-1.oci.customer-oci.com/p/x3c6dl2qfNZsDPc-JZrqIhRn3xzFhMvEz_7wHM1FFXpkxE8_wMXctQZCts4NVm76/n/axqxbktknqat/b/image_bucket/o/blog/FastPerm/3_FastPerm_3_3.gif)

두 함수는 모두 Cell이 어느 sample에 속해있는지에 대한 annotation 정보를 2차원 boolean 행렬로 만들어 count matrix와 행렬곱 연산을 수행합니다. 그러나 이 방식의 문제점은 결과값에 아무 영향을 미치지 못하는 0의 비율이 매우 높음에도 불구하고 오직 행렬곱 연산을 위해 count table이나 annotation table로의 **불필요한 메모리 접근이 과도하게 발생**한다는 것입니다.


### 여러가지 시도
---

행렬곱 연산보다 연산 효율을 올리기 위해 다양한 시도들을 해보며, 10회의 pseudobulk로 performance time을 측정했습니다.

![](https://axqxbktknqat.objectstorage.ap-chuncheon-1.oci.customer-oci.com/p/x3c6dl2qfNZsDPc-JZrqIhRn3xzFhMvEz_7wHM1FFXpkxE8_wMXctQZCts4NVm76/n/axqxbktknqat/b/image_bucket/o/blog/FastPerm/3_FastPerm_3_4.png)

1. **단순 반복** (synchronous): C++의 성능을 믿고 순차적으로 full table을 순회하면서 누산하도록 만들어 보았습니다. 그러나 이 방법은 R 스크립트보다도 성능이 나빴습니다. 연산에 불필요한 0값을 불러오는 메모리 접근이 줄어들지 않았으니 당연합니다.
2. **멀티스레딩** (synchronous w/o mutex): 여러 스레드를 생성해 full table을 순회하며 pseudobulk를 해 보았습니다. 속도는 빨라졌지만, pseudobulk table의 값에 오류들이 생깁니다. 여러 스레드가 동시에 pseudobulk table의 같은 위치에 접근하게 되는 race condition을 일으켰기 때문입니다. 통계 프로그램이 이러면 안되죠.
3. **멀티스레딩 + mutex** (synchronous with mutex): 오류 없이 병렬처리가 되도록 pseudobulk table의 column마다 mutex 처리를 했습니다. 값에 오류는 없어졌지만, context switching으로 인해 단순 반복보다도 속도가 저하됩니다. 



## 최적화 1 - Sparse Matrix Conversion
---

멀티스레딩이 연산 효율을 올린다는 사실은 명확하지만, 여전히 값에 오류가 없도록 여러 스레드가 안전하게 병렬처리할 방법이 필요했습니다. 저는 count table이 0의 비중이 높은 sparse matrix라는 특징에 주목했습니다. 이전 포스트에서 다루었듯, count matrix의 50% ~ 90%를 차지하는 0값들(sparsity)은 psedobulk 과정에서 연산 결과에 영향을 전혀 미치지 않습니다. 그렇다면 **오직 non-zero값들만 모아 멀티스레딩을 하기 편리한 자료 구조로 count matrix를 변환**해둔다면 연산 효율성이 올라가지 않을까요?

Sparse matrix를 압축하는 방법에는 LIL, COO, CSR, CSC 등 다양한 방법[^1]이 있습니다. 저는 이 중에서 LIL(List of Lists)를 선택했습니다. LIL(List of Lists)은 COO(Coordination format)의 변형된 방법으로 생각할 수 있습니다. COO는 (row index, col index, value)로 된 triplet을 저장하는 반면, LIL은 column을 보존하면서 (row index, value) 쌍을 저장합니다. 

그림으로 count table을 LIL로 변환하는 과정을 살펴보겠습니다.

![](https://axqxbktknqat.objectstorage.ap-chuncheon-1.oci.customer-oci.com/p/x3c6dl2qfNZsDPc-JZrqIhRn3xzFhMvEz_7wHM1FFXpkxE8_wMXctQZCts4NVm76/n/axqxbktknqat/b/image_bucket/o/blog/FastPerm/3_FastPerm_3_5.png)

(row index, value) 쌍이 누적되어 있는 column 리스트들의 리스트로 변환되었습니다[^2]. 한 번의 압축만 수행하면 모든 N번의 permutation에서 상대적으로 아주 작은 크기의 메모리만 참조하면 됩니다.

여러 자료 구조 중에서 LIL을 선택한 가장 큰 이유는 column에 대한 정보가 그대로 보존되기 때문입니다. 

스레드를 한 명의 사람이라고 가정합시다. 이 사람은 본인으로부터 나온 세포(column)의 정보들을 row-wise하게 연산해서 하나의 열로 압축해야 하는 일을 할당받았습니다. 즉, 본인이 수집해서 **누산해야 하는 cell들의 index 리스트만 넘겨받는다면**[^3], pseudobulk table에서 다른 **누구와도 메모리 영역을 공유하지 않으면서 비동기적으로 연산**을 수행할 수 있습니다! 

![](https://axqxbktknqat.objectstorage.ap-chuncheon-1.oci.customer-oci.com/p/x3c6dl2qfNZsDPc-JZrqIhRn3xzFhMvEz_7wHM1FFXpkxE8_wMXctQZCts4NVm76/n/axqxbktknqat/b/image_bucket/o/blog/FastPerm/3_FastPerm_3_6.png)

예를 들어 Lucy 스레드의 경우를 살펴보면, pseudobulk해야 하는 cell들로서 B와 F column을 할당받았습니다. column B에 있는 첫 번째 쌍은 (2,1)로, pseudobulk table의 두 번째 row, lucy column에 1을 더하게 됩니다. 이를 F column의 쌍들에 대해서도 반복하면 됩니다.

![](https://axqxbktknqat.objectstorage.ap-chuncheon-1.oci.customer-oci.com/p/x3c6dl2qfNZsDPc-JZrqIhRn3xzFhMvEz_7wHM1FFXpkxE8_wMXctQZCts4NVm76/n/axqxbktknqat/b/image_bucket/o/blog/FastPerm/3_FastPerm_3_7.gif)

여러 스레드가 동시에 연산되는 과정입니다. 스레드끼리 독립적인 열에만 접근하고 있어 race condition을 일으키지 않습니다.

이제는 mutex를 사용하지 않고도 안전하고 빠르게 멀티스레딩을 할 수 있게 되었습니다.



## 최적화 2 - Rank Comparison
---

메모리 차원에서도 몇 가지 방법으로 최적화를 수행했습니다.

gene 20,000개에 대해 permutation을 한다면 매번 20,000개의 lfc값들이 저장됩니다. 이걸 모두 저장하여 마지막에 permutation의 rank를 구하게 됩니다. permutation 횟수가 400,000회일 때 runtime에 필요한 RAM의 용량은 아래와 같습니다.

$$20000\frac{N_{double}}{N_{permutation}}\times400000N_{permutation}\times8\frac{Byte}{N_{double}} = 64,000,000,000Byte = 64GB$$

무려 RAM 64GB가 필요합니다. 심지어 한번에 잡고 시작하는 것도 아니고 runtime동안 점점 늘어나면서 64GB를 차지하게 됩니다. p-value를 구하기 위해 알아야 하는 것은 gene별 observed lfc value의 rank였습니다. 하지만 **rank를 알기 위해 정말로 모든 값들이 다 필요할까요?**

사실 rank를 구하는 데 모든 값을 다 저장할 필요는 없습니다. **자기보다 큰 숫자가 몇 회 나왔는지만** 알면 됩니다.

예를 들어 5번의 permutation에서, gene A의 observed lfc value는 3이고, 나머지가 1,2,4,5였다면, 자신보다 큰 것이 2개이므로 $$2+1 = 3$$ 이 곧 자신의 rank가 됩니다. 따라서 p-value도 $$\frac{N_{big}+1}{N_{permutation}}$$ 가 됩니다.

즉, 아무리 많이 permutation을 돌리더라도 각 gene마다 observed lfc value보다 컸던 simulated lfc value의 개수를 카운팅하는 **정수 1개씩만 있으면 간단하게 p-value를 계산**할 수 있습니다.



## 성능 개선 비교
---

![](https://axqxbktknqat.objectstorage.ap-chuncheon-1.oci.customer-oci.com/p/x3c6dl2qfNZsDPc-JZrqIhRn3xzFhMvEz_7wHM1FFXpkxE8_wMXctQZCts4NVm76/n/axqxbktknqat/b/image_bucket/o/blog/FastPerm/3_FastPerm_3_8.png)
pseudobulk step에서 count matrix를 LIL로 변환한 멀티스레딩 알고리즘을 적용한 경우, 꾸준히 200ms 미만의 시간 안에 처리됩니다. 단순 full table을 synchronous하게 순회하는 경우가 1400ms 언저리로 측정되는 것에 비하면 매우 빠른 속도입니다. 




## 참고 자료
---
- [scRNA-seq dataset Quality Control basics](https://www.singlecellcourse.org/basic-quality-control-qc-and-exploration-of-scrna-seq-datasets.html)
- [edgeR User Guide](https://www.bioconductor.org/packages/devel/bioc/vignettes/edgeR/inst/doc/edgeRUsersGuide.pdf)
- [LIL; List of Lists format](<https://en.wikipedia.org/wiki/Sparse_matrix#List_of_lists_(LIL)>)



[^1]: List of Lists, Coordinate list, Compressed sparse row, Compressed sparse column

[^2]: Pseudobulk table은 vector\<vector\<GeneVal>> 로 선언됩니다. GeneVal이라는 구조체를 담는 벡터들의 벡터이며, GeneVal은 row index와 value 두 값을 멤버변수로 갖는 구조체입니다.

[^3]:permutation에서는 column 인덱스를 나눠주는 방식만 다릅니다. observed lfc를 계산할 떄는 coldata(cell의 sample 출처를 나타낸 annotation)를 사용해 cell의 소속을 찾아 인덱스를 분배해주지만, permutation에서는 case/control group에 상관없이, 원래 샘플이 갖고있던 cell 개수만큼 인덱스를 랜덤하게 섞어 분배하도록 구현했습니다. 
