---
layout: post
title: "scRNA-seq 데이터 순열 검정 프로그램, FastPerm 제작기 (2)"
date: 2023-11-17 00:00:00 +0900
categories: 
  - tech
  - project
related_posts:
  - _posts/tech/project/2023-11-14-FastPerm_1.md
  # - _posts/tech/project/2023-11-14-FastPerm_3.md
---

* toc
{:toc}


## 비모수 검정법의 장점
---

이전 포스트에 이어서, 찾고자 하는 방법은 아래와 같습니다.

single-cell data의 단점을 보완하기 위한 pseudobulk를 사용하면서 낮은 검정력 문제를 회피할 수 있는 방법
{:.message}

|      |              Bulk data               |             Single cell data             |           Pseudobulk data            |
| :--: | :----------------------------------: | :--------------------------------------: | :----------------------------------: |
| Pros |           다양한 툴, 분석 방법 간단            | cell type별 분석 가능<br>많은 sample size 확보 가능 | cell type별 분석 가능<br>분석 가능한 gene이 많아짐 |
| Cons | Cell type 구별 불가<br>(적은 샘플일 때) 낮은 검정력 |  분석 가능한 gene이 적음<br>심각한 false positive   |          (적은 샘플일 때) 낮은 검정력           |

pseudobulk 방법을 수행하면 sample size가 작아집니다. 즉 이 상태에서는 두 집단 간의 차이가 꽤 크더라도 "확률적으로 그럴 수 있는 경우[^1] "로 납득이 되어버버리고, 실제로는 DEG인데도 non-DEG로 판정되어버리는 문제[^2]가 발생할 수 있습니다. 

그럼 sample size가 p-value에 영향을 주지 않는 검정 방법을 쓰면 어떨까? 하는 것이 [하은지 박사](https://scholar.google.com/citations?user=ZQA9ySsAAAAJ&hl=ko)님의 생각이었습니다.

모수를 추정하는 검정(Parametric test)는 주어진 값들을 가지고 분포를 가정[^3]하고, 모수를 추정하여, 두 집단의 분포가 얼마나 다른지를 확률적으로 판정합니다. 이에 반해, 비모수검정법(non-parametirc test)은 분포를 가정하지도, 모수를 추정하지도 않기 때문에, 관측값들이 적은 상황에서도 사용 가능하다는 장점이 있습니다. 

그 중에서도 순열검정법(Permutation test)을 선택[^4]해 사용하기로 했습니다.


[^1]:통계적으로 말해, 큰 p value를 가지며, 넓은 confidence interval를 가지는 경우
[^2]: Statistical power가 낮음 (beta error; type 2 error)
[^3]: RNA-seq data의 확률분포는 주로 negative binomial distribution (음이항분포)가 사용됩니다.
[^4]: Sample size를 조정해 FDR control에 용이하기 때문. 자세한 이유는 후술.






## Pseudobulk data에서 permutation의 적용
---

순열검정법이 DE analysis에 어떻게 적용되는지 예시를 통해 살펴보겠습니다.
어느 Gene A의 single-cell data로부터 pseudobulk된 값들이 아래와 같다고 가정합시다.
case 샘플들과 control 샘플들이 서로 다른 분포로부터 나왔는지를 알아보고자 합니다.

|         |     |     |     |     |     |     |     |
| :-----: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |
|  case   |  1  |  1  |  3  |  1  |  4  |  5  |  6  |
| control |  7  |  8  |  5  | 12  |  7  | 11  | 10  |

Permutation test의 가정은 다음과 같습니다.

두 집단의 분포가 같다면, 값을 섞어 임의의 두 집단으로 나누더라도 두 집단의 차이는 0에 가까울 것이다.
{:.message}

만일 실제 통계값이 시뮬레이션한 여러 값들 사이에서 나올 수 있는 범위 안에 속해 있다면, 두 집단은 실제로 같은 분포였을 것입니다. 하지만 반대로 **관측값들이 다른 분포로부터 나온 값이라면**, 두 집단의 평균의 차이가 시뮬레이션한 히스토그램에서 **극단적인 위치에 있을 것**입니다. 

보통은 두 집단의 차이를 구하기 위해 평균간 차이값을 사용하지만, RNA-seq data 분석에서는 주로 log2 fold change[^5]를 사용합니다. 

$$log_2(\frac{\bar{X}_{case}}{\bar{X}_{control}})$$

이 경우 permutation test의 작동 알고리즘은 아래와 같습니다.
1. 모든 샘플을 합쳐 섞은 후 임의의 두 집단으로 나눔
2. 두 집단의 log2 fold change를 구해 저장
3. 1-2의 과정을 $$N_{permutation}$$회 반복
4. 저장한 lfc 값들을 정렬하여, 실제 lfc 값이 위치하는 순위($$rank_{lfc}$$)를 구함. 
5. p-value를 구함.

$$p-value = \frac{rank_{lfc}}{N_{permutation}}$$

위의 알고리즘을 실행하여 histogram으로 보여주는 파이썬 코드입니다.

```python
import numpy as np
import math
import random as rd
from tqdm import tqdm
import matplotlib.pyplot as plt

class Permutation() :
    def __init__(self, case, ctrl, N):
        self.case = case
        self.ctrl = ctrl
        self.N = N
        self.true_lfc = self.calc_lfc(case, ctrl)
        self.simulated_lfcs = []
        self.p_val = 0

    # copy the list and return the shuffled list
    def shuffle(self, list1, list2) -> list :
        assert len(list1) == len(list2)
        shuffled_list = list1 + list2
        rd.shuffle(shuffled_list)
        return shuffled_list[:len(list1)], shuffled_list[len(list1):]  

    # calculate the lfc of the two list
    def calc_lfc(self, list1, list2) -> int :
        lfc = np.log2(np.mean(list1) / np.mean(list2))
        return lfc
  
    # plot a histogram of the result
    def plot(self, rank) :
        plt.hist(self.simulated_lfcs, bins=20, alpha=0.8, color="#3392b5")
        plt.xlim(xmin=-2, xmax=2)
        plt.title("Histogram of log2 fold changes")
        plt.vlines(self.true_lfc, ymin=0, ymax=self.N/10 - 100, linestyles="dotted", colors="black")
        plt.text(self.true_lfc - 0.2, self.N/10, "lfc : {}\np-value : {}".format(round(self.true_lfc,3), self.p_val))
        plt.show()

    # execute permutation
    def simulate(self) :
        # get simulated lfc values
        for _ in tqdm(range(self.N)) :
            s_list1, s_list2 = self.shuffle(self.case, self.ctrl)
            simulated_lfc = self.calc_lfc(s_list1, s_list2)
            self.simulated_lfcs.append(simulated_lfc)
        
        # get the p-value
        self.simulated_lfcs.sort()
        rank=0
        for i in range(self.N) :
            if self.true_lfc < self.simulated_lfcs[i] :
                rank = i
                break
        self.p_val = rank/self.N

        # two-tailed adjustment
        if self.p_val > 0.5 :
            self.p_val -= 0.5
        self.p_val*=2

        # plot
        self.plot(rank) 

if __name__ == "__main__" :

    case=[1,1,3,1,4,5,6]
    ctrl=[7,8,5,12,7,11,10]
    simulator = Permutation(case, ctrl, 100000)
    simulator.simulate()
    
```

N=100,000으로 반복했을 때 아래와 같은 결과를 얻을 수 있습니다.

![](https://axqxbktknqat.objectstorage.ap-chuncheon-1.oci.customer-oci.com/p/x3c6dl2qfNZsDPc-JZrqIhRn3xzFhMvEz_7wHM1FFXpkxE8_wMXctQZCts4NVm76/n/axqxbktknqat/b/image_bucket/o/blog/FastPerm/2_Figure_1.png)

observed lfc value는 시뮬레이션으로 얻은 lfc값들에 비해 극단에 위치합니다. p-value에 따르면, case와 control이 같은 분포였을 확률은 0.2%에 불과합니다. 따라서 귀무가설을 기각하고 두 집단이 다른 분포였음(대립가설)을 채택하게 됩니다. 

반면, 눈대중으로 보기에도 큰 차이가 없도록 case 값들을 수정하여 코드를 돌리면 다음과 같은 결과를 얻습니다.


|         |     |     |     |     |     |     |     |
| :-----: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |
|  case   |  8  |  6  | 10  |  7  |  9  | 10  |  7  |
| control |  7  |  8  |  5  | 12  |  7  | 11  | 10  |


![](https://axqxbktknqat.objectstorage.ap-chuncheon-1.oci.customer-oci.com/p/x3c6dl2qfNZsDPc-JZrqIhRn3xzFhMvEz_7wHM1FFXpkxE8_wMXctQZCts4NVm76/n/axqxbktknqat/b/image_bucket/o/blog/FastPerm/2_Figure_2.png)


lfc의 범위도 크지 않을 뿐더러, observed lfc value 또한 훨씬 더 0에 가까운 값을 얻었습니다. p-value가 0.79이므로 not significnat합니다.

permutation test는 전체 시뮬레이션값들 중 관측값이 위치하는 rank와 permutation의 횟수가 p-value를 결정합니다. 여러 non-parametric test들 중에서도 permutation test를 선택한 이유는 바로 이러한 이유입니다. sample size가 적으면 p-value가 심각하게 영향을 받는 parametric test들과는 달리 비교적 안정적인 p-value 값을 얻을 수 있기 때문입니다.



[^5]: 두 집단의 평균값을 분자와 분모에 놓고 log2를 취한 값입니다. 정하기 나름이지만 case를 분자에, control을 분모에 놓는다고 하면, lfc가 양수일 때 case에서 더 많이 발현, 음수일 때 case에서 저발현, 0에 가까우면 두 집단에서 발현량의 차이가 크게 없다는 결론을 내릴 수 있겠습니다.




## 시간의 문제
---

이런 괜찮은 접근이 지금까지 시도되지 않았던 이유는 **시간이 무지막지하게 오래 걸리기 때문**입니다.

single-cell RNA-seq 데이터의 RNA count table 크기는 row[^6]가 2만-3만개, column[^7]이 1만-5만정도입니다. case 5명, control 5명이 각각 cell 1000개씩 구성하고 있는 경우를 예시로 하여 필요한 연산 절차를 알아봅시다.
1. 각 column을 랜덤하게 섞어 case와 control 집단으로 임의 분배
2. column을 같은 샘플끼리 그룹화하여 $$20,000\times10,000$$ 의 table에서 $$20,000\times10$$로 압축
3. 모든 gene에 대해 돌아가면서 simulated lfc값 수집
4. 1-3의 과정을 $$N_{permutation}$$회만큼 수행 (보통 몇십만회에 달함)

R 스크립트 언어를 사용해 이 과정을 돌리려면 200,000회의 permutation에 약 720시간(한 달)의 시간이 소요됩니다. 그것도 하나의 cell type에 대해서만요. 

시간 뿐만 아니라 메모리 공간도 문제입니다. gene 20,000개에 대해 permutation을 한다면 매번 20,000개의 lfc값들이 저장되고, 추후 gene별로 순서대로 정렬해 실제 lfc값의 rank를 알 수 있습니다. permutation을 100,000회만 한다고 해도 $$20,000 \times 100,000 = 2,000,000,000$$ 개의 숫자가 저장됩니다. 좋게 봐줘서 숫자 하나에 4Byte라고 해도 프로그램이 한 번에 들고 있어야 하는 메모리의 양이 $$8,000,000,000 Byte = 7.4GB$$ 나 됩니다.

이렇게 시간상으로도, 메모리상으로도 엄청난 자원 소모가 있기 때문에 single cell 데이터에서 permutation은 잘 쓰이지 않는 방법이었습니다. 만일 parametric DE test를 수행해주는 R package인 edgeR이나 DESEq2를 사용하면, 한 번의 분포 fitting만으로도 결과를 알 수 있으니 굳이 이렇게까지 할 이유가 없겠죠. 

그렇다면 왜 시간과 메모리를 소모하면서 permutation의 횟수를 몇십만회씩이나 수행해야 할까요?



## False Discovery Rate
---

단일 검정에서는 유의 수준 alpha를 0.05로 설정하면 5%의 우연으로 오류가 발생합니다. 그러나 같은 alpha값 0.05더라도 **20,000개의 gene을 동시에 검정하면 필연적으로 약 1000개는 잘못된 결과**를 얻게 됩니다. 그래서 통계 검정을 동시에 여러 번 수행할 때는 얻은 p-value를 더 보수적으로 보정해줌으로써[^8] 이러한 오류를 피합니다. 이 과정을 FDR(False Discovery Rate) control 이라고 합니다.

Permutation test의 결과로, gene A의 p-value가 0.01이 나왔다고 가정합시다. 문제는, 현재 gene A 뿐만이 아닌 gene B, gene C 등등을 동시에 검정하고 있고, 다중 검정 문제를 피하기 위해 해당 p-value에 어떤 factor를 곱해서 더 크게 만들 예정이라는 것입니다. BH method를 기준으로 생각해봅시다. p-value에 곱할 factor는 다음과 같이 계산됩니다. 

> $$\frac{N_{pvalues}}{rank}$$ (p-value의 총 개수 / 해당 p-value의 rank )

테스트한 gene의 갯수가 20,000개이고, gene A의 p-value가 모든 p-value들 중 가장 작다면, adjusted p-value는 아래와 같이 계산됩니다.

$${p}_{adj}= 0.01 \times \frac{20000}{1} = 200$$ [^9]

즉, 아무리 p-value가 작게 나오더라도 한번에 테스트하는 횟수가 너무 많아 곱해지는 factor가 너무 강하면 p-value가 모두 not significant해지는 결과를 얻을 수도 있게 됩니다. 이 문제를 방지하려면 permutation의 횟수를 충분히 늘려 FDR 과정에서 어떤 factor가 곱해지더라도 p-value가 alpha보다 작아지게 만들어주면 됩니다[^10].

그렇다면 p-value가 충분히 작아지게 하기 위해 필요한 permutation의 횟수는 얼마일까요? 여러 p-value들 중에서 가장 작은(가장 유의하며 반드시 DEG여야 할) p-value에 곱해질 factor는 아래와 같습니다. 

$$\frac{N_{pvalues}}{rank}$$

이 값이 원래 p-value와 곱해진 후에도 유의 수준(alpha)보다 작기 위해서는 아래의 식을 만족해야 합니다.

$${p}_{adj}=\frac{rank_{lfc}}{N_{permutation}}\times\frac{N_{pvalues}}{rank} <= a$$

p-value의 rank와 lfc의 rank가 모두 1등인, 매우 극단적인 경우를 상정하고 $$N_{permutation}$$ 의 기준에서 정리하면 다음과 같습니다.

$$N_{permutation} >= \frac{N_{pvalues}}{a}$$

테스트한 gene의 개수($$N_{pvalues}$$)를 20,000개, 유의 수준 α를 0.05로 설정한다면 $$N_{permutation}$$은 최소 400,000 이상이 됩니다. 정리하면, gene 2만개를 test하고 α=0.05로 설정하면, 아무리 적어도 400,000회는 permutation해야 가장 작은 p-value들이 adjustment 후에도 alpha보다 작을 수 있다는 의미가 됩니다.



[^6]: gene의 개수

[^7]: cell의 개수

[^8]: BH, bonferroni 등의 보정 방법으로 기존의 p-value보다 크게 만들어주는 방법이 사용됩니다. 이렇게 얻은 p-value를 조정된(adjusted) p-value라고 합니다.

[^9]: 실제로는 p-value가 1을 넘기면 의미가 없지만, 다중 검정 상황에서는 곱해지는 factor가 p-value보다 훨씬 클 수도 있다는 예시를 보이기 위해 사용했습니다.

[^10]: permutation 횟수를 무한정 늘리면 p-value도 무한정 작아지게 되므로, 모든 gene을 DEG로 판별할 수도 있는 위험이 있다고 생각할 수 있습니다. 그러나 rank가 어느 값으로 수렴해버리면 p-value가 무한정 작아지지 않습니다. 하지만 observed lfc value가 극단의 위치에 있다면 p-value는 무한정 작아질 수 있고, 이러한 경우가 바로 FDR control 과정에서 보정 factor를 곱하더라도 DEG로 판정되어야만 하는 gene이라고 할 수 있겠습니다.




## 지금까지의 상황..
---

기존의 상황을 다시 정리하자면...
- 왜 scRNA-seq data를 을 pseudobulk하는 과정을 거치는가?  

scRNA-seq data를 그대로 통계 검정에 투입하면 sample size가 너무 큰 탓에, 미미한 그룹 간의 차이에도 **통계적 유의성이 극단적으로 크게 나오는 문제**(false positive)가 발생하기 때문입니다.
{:.message}

- 그럼 처음부터 bulk로 하지, 왜 scRNA-seq data에서 pseudobulk로 다시 합쳐야 하는가?

single-cell 데이터로부터 cell-type을 나누어서 볼 수 있기 때문입니다. 다시 말해 **분석의 resolution이 좋아집니다.** bulk에서는 cell type이고 뭐고 다 갈아버려서 한 샘플의 종합적인 유전자 발현 경향만 알 수 있습니다.
{:.message}

- pseudobulk를 하면 좋은 점은? 

cell type별로 DE test를 수행할 수 있고, single-cell data로 DE test를 했을 때 생기는 false positive 문제가 확연히 줄어들며, 0값이 줄어들어 test 가능한 gene의 개수가 늘어납니다.
{:.message}

- permutation이 필요한 이유는?

pseudobulk를 하더라도 sample size가 너무 적다면 bulk처럼 검정력이 낮아집니다. 그래서 **sample size에 영향을 받지 않는** non-parametric test인 permutation을 통해 단점을 보완하고자 합니다.
{:.message}

- permutation 횟수가 왜 그렇게 많이 필요한가?

많은 gene을 동시에 검정할 때 p-value들은 값이 커지는 방향으로 조정됩니다. 이 때, 작아야 할 값들이 충분히 작게 유지되어 **false negative가 생기는 것을 방지하기 위해** permutation 횟수를 최소 수치 이상으로 설정하게 됩니다.
{:.message}

Permutation test가 갖는 여러 장점에도 불구하고, scRNA-seq data처럼 큰 데이터를 몇십만회씩 pseudobulk하는 과정은 시간을 극심하게 소모합니다. 교수님께서는 이 과정을 R 스크립트가 아니라 C++와 같이 퍼포먼스가 좋은 언어로 수행하면 속도를 개선할 수 있을 것이라고 생각하습니다.  그래서 제가 유전체학 연구실에 들어갔을 때 처음 맡게 된 일은 **scRNA-seq data의 pseudobulk 기반 permutation DE test를 수행하는 성능 좋은 프로그램을 개발**하는 것이었습니다.


## 참고 자료
---
- **[Permutation test](https://en.wikipedia.org/wiki/Permutation_test)**
- [순열검정법](https://angeloyeo.github.io/2021/10/28/permutation_test.html)
- [False positive rate (FDR)](https://youtu.be/K8LQSvtjcEo?si=WMUJKiNneg7ZU2Dy)


