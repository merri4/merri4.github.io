---
layout: post
title: "XAI 인공지능을 해부하다 (1) - 배경"
date: 2025-02-12 00:00:00 +0900
categories: 
  - tech
  - xai
# related_posts:
#   - _posts/tech/xai/2025-?-?-xai_2.md
---

2021년에 제작된 책. 


## Background
---
DARPA 프로젝트에서 2016년에 XAI 프로젝트(DARPA-BAA-16-53)가 승인되었다. DARPA는 인터넷의 전신인 ArpaNet, GPS, 스텔스기를 만든 미국의 국방기술 연구기관이다. 21년 프로젝트가 종료되어 [회고 보고서](https://forest62590.tistory.com/73)가 나왔는데, 결론만 보자면 현재의 기술로는 구현 가능하지 않다는 결론이다. 하지만 여러가지 시사점을 준다. 

- 사용자는 의사결정과 설명을 함께 제공하는 시스템을 선호한다.
- 설명은 AI가 정확하지 않을 때 도움이 되며, 극단적 경우(edge cases)에 유용하다
- 설명의 효율성을 측정하기 난해하다
- 컴퓨터 공학, 인공지능, 심리학 등 여러 분야에 걸친 긴밀한 협업이 필요

프로젝트가 종료된 뒤로도 AI는 빠르게 발전하고 있다. 특히 프로젝트 종료 1년 뒤인 22년에 chatGPT와 stable diffusion이 엄청난 광풍을 일으키며 AI의 발전을 특이점에 더 가깝게 만들고 있다. 하지만 모델의 내부를 해석하는 XAI 분야는 여전히 AI 자체의 발전 속도를 따라가지 못하고 있다.


## XAI란?
---
AI가 어떤 근거로 의사결정을 내렸는지를 알 수 있게 설명 가능성을 추가하는 기법이다. 주요 기법들은 실제적으로 결과를 시각적으로 확인하기에 편리한 CNN에서 주로 발달했다. 대표적으로 다음과 같은 실제적인 기법들이 있다. 

- Feature Importance
- Filter Visualization
- LRP (Layer-wise Relevance Propagation)

XAI는 사용자와의 상호작용(HCI) 측면에서도 유용할 수 있지만, 모델 자체의 정확도를 올리고 데이터를 정제하는 feedback 과정에도 유용하게 사용할 수 있다. 

DARPA가 제시하는 3가지 XAI의 방향은 explainable feature, Interpretable model, Model Induction이다. 



