---
layout: post
title: "[논문 리뷰] Delving into Masked Autoencoders for Multi-Label Thorax Disease Classification"
date: 2023-03-15 00:00:00 +0900
categories: 
  - tech
  - paperreview  
---

* toc
{:toc}


[논문 링크](https://arxiv.org/abs/2210.12843)

[ViT](https://velog.io/@leehyuna/Vision-TransformerViT)를 [MAE](https://developers-shack.tistory.com/13) 방식으로 학습하여 chest X-ray classification task에서 CNN(DenseNet-121)과 성능을 비교한 CV 논문입니다. ViT를 학습할 때 몇 가지 중요한 hyperparameter, pre-training recipe등을 제공합니다. 학사 졸업 연구에 사용하기 위해 recipe 및 아이디어를 참고했습니다. WACV(2023).


## Summary
---
#### Objective
- ViT는 CNN보다 좋은 성능을 가지는 반면 학습에 요구하는 데이터량이 훨씬 많아, 데이터가 부족한 medical domain에 적용하기에는 challenging한 상황입니다. 그래서 아직까지는 CNN 또는 CNN+ViT hybrid model을 사용하곤 합니다.
- 본 논문에서는 ViT에게 대량의 medical 데이터를 학습시키고 좋은 fine-tuning recipe를 거친다면 CNN에 필적하는 성능을 보이는지 평가하고자 합니다.

#### MAE
- Foundation Model로서 CNN을 pre-training할 때는 보통 contrastive learning, predictive learning, restorative learning 등을 사용하는데, 이러한 학습 방법들은 ViT 아키텍쳐에 아직 adaptation되지 않았습니다. 그래서 여기에서는 MAE(Masked Autoencoders)를 채택해 ViT를 학습시킵니다.
- MAE는 input patch를 random masking해서 모델이 missing pixel을 재구성하도록 학습시키는 self-supervised learning 방법입니다.
- 이렇게 구성한 foundation model을 특별한 recipe로 fine-tuning하여, 3개의 chest X-ray dataset에 적용하여 성능을 평가합니다.


## Method
---
- Data : NIH ChestX-ray14 + Stanford CheXpert + MIMIC-CXR
- Augmentation : random resized cropping, random horizontal flipping
- Pre-training Task : image reconstruction
- Error Function : MSE
- Decoder는 pre-training 과정에서 masked patch를 재구성하기 위해서만 사용


## Pre-training & Fine-tuning Recipe
---
여러 pre-training data를 사용해 DenseNet-121과 ViT를 비교했고, 전반적으로 CNN이 우수하나 pretrain양이 많을 때 ViT도 유사한 성능을 보였습니다. Fine-tuning 시에는 Stanford CheXpert, COVIDx, NIH chestX-ray14 데이터셋을 사용했습니다. 자세한 recipe는 너무 domain-specific한 내용들이라 생략합니다. 


## Discussion
---
- MAE로 학습하였기 때문에 원본 이미지의 anomaly도 판별 가능 - 일부러 anomaly를 추가해 사진을 재구성하도록 모델에 통과시킨 결과, 모델은 anomaly들을 제거하였음
- Grad-CAM을 사용해 model prediction에 영향을 미친 heatmap을 그려보았을 때 (DenseNet-121에서는 4th dense block을, ViT에서는 마지막 LayerNorm 사용) CNN에서 Grad-CAM에 의한 localization이 훨씬 더 잘 작동합니다. 
- ViT에 대한 explainablity 후속 연구도 필요합니다.